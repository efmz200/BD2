# An Inside Look at Google BigQuery
## How Google Handles Big Data Daily Operations
Google handles Big Data every second of every day to provide services like Search, YouTube, Gmail and Google Docs. Dremel is a query service that allows you to run SQL-like queries against very, very large data sets and get accurate results in mere seconds.
# BigQuery: Externalization of Dremel
BigQuery is the public implementation of Dremel that was recently launched to general availability. BigQuery provides the core set of features available in Dremel to third party developers. It does so via a REST API, a command line interface, a Web UI, access control and more, while maintaining the unprecedented query performance of Dremel.

Dremel Can Scan 35 Billion Rows Without an Index in Tens of Seconds Dremel, the cloud-powered massively parallel query service, shares Google’s infrastructure, so it can parallelize each query and run it on tens of thousands of servers simultaneously. 
# Columnar Storage and Tree Architecture of Dremel

1. Columnar Storage. Data is stored in a columnar storage fashion which makes possible to achieve very high compression ratio and scan throughput.
2. Tree Architecture. is used for dispatching queries and aggregating results across thousands of machines in a few seconds.

# Columnar Storage
Dremel stores data in its columnar storage, which means it separates a record into column values and stores each value on different storage volume, whereas traditional databases normally store the whole record on one volume.
- Traffic minimization.
- Higher compression ratio.
Columnar storage has the disadvantage of not working efficiently when updating existing records.

# Tree Architecture
The architecture forms a massively parallel distributed tree for pushing down a query to the tree and then aggregating the results from the leaves at a blazingly fast speed. 
# BigQuery versus MapReduce
This is the difference:

- Dremel is designed as an interactive data analysis tool for large datasets • MapReduce is designed as a programming framework to batch process large datasets

Moreover, Dremel is designed to finish most queries within seconds or tens of seconds and can even be used by non-programmers, whereas MapReduce takes much longer (at least minutes, and sometimes even hours or days) to finish processing a dataset query.

# Comparing BigQuery and MapReduce
MapReduce is a distributed computing technology that allows you to implement custom “mapper” and “reducer” functions programmatically and run batch processes with them on hundreds or thousands of servers concurrently.
# MapReduce Limitations
MapReduce is designed as a batch processing framework, so it’s not suitable for ad hoc and trial-and-error data analysis. The turnaround time is too slow, and doesn’t allow programmers to perform iterative or one-shot analysis tasks on Big Data.
# Data Warehouse Solutions and Appliances for OLAP/BI
In OLAP/BI, you roughly have the following three alternatives for increasing the performance of Big Data handling.
- Relational OLAP (ROLAP)
- Multidimensional OLAP (MOLAP) • Full scan
# Relational OLAP (ROLAP)
ROLAP is an OLAP solution based on relational databases (RDB). In order
to make RDB faster, you always need to build indices before running OLAP queries. 
# Multidimensional OLAP (MOLAP)
MOLAP is an OLAP solution that is designed to build data cubes or data marts based on dimensions predefined during the design phase.
# Full-scan Speed Is the Solution
As you can see, neither ROLAP or MOLAP is suitable for ad hoc queries or trial- and-error data analysis, as you need to define all the possible queries at design or import time.

Traditional data warehouse solutions and appliances have tried to achieve better disk I/O throughput with the following technologies:
- In-memory database or flash storage.
- Columnar storage. 
- Parallel disk I/O.